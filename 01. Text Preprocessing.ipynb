{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Fine Food Reviews Analysis\n",
    "\n",
    "Data source : https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "\n",
    "The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.\n",
    "\n",
    "Number of reviews: 568,454\n",
    "Number of users: 256,059\n",
    "Number of Products: 74,258\n",
    "Timespan: Oct 1999 - Oct 2012\n",
    "Number of Attributes/Columns in data: 10\n",
    "\n",
    "Attribute Information:\n",
    "1. Id\n",
    "2. ProductId - unique identifier for the product\n",
    "3. UserId - unique identifier for the user\n",
    "4. ProfileName\n",
    "5. HelpfulnessNumerator - number of users who found the review helpful\n",
    "6. HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not\n",
    "7. Score - rating between 1 and 5\n",
    "8. Time - timestamp for the review\n",
    "9. Summary - brief summary of the review\n",
    "10. Text - text of the review\n",
    "\n",
    "#### Objective\n",
    "\n",
    "Given a review, determine whether the review is positive (Rating of 4 or 5) or negative (rating of 1 or 2).\n",
    "\n",
    "[Q] How to determine if a review is positive or negative?\n",
    "\n",
    "[Ans] We could use the Score/Rating. A rating of 4 or 5 could be considered a positive review. A review of 1 or 2 \n",
    "could be considered negative. A review of 3 is neutral and therefore ignored. Note that this is an approximate and proxy way of determining the polarity (positivity/negativity) of a review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "The dataset is available in two forms\n",
    "1. .csv file\n",
    "2. SQLite database\n",
    "\n",
    "In order to load the data, We have used the SQLITE dataset as it is easier to query the data and visualise the data effectively.\n",
    "\n",
    "Here as we only want to get the global sentiment of the recommendations (positive or negative), we will purposefully ignore all Scores equal to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints in our data (100000, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the SQLite Table to read data.\n",
    "con = sqlite3.connect('database.sqlite')\n",
    "\n",
    "# Filtering only positive and negative reviews i.e. not taking\n",
    "# into consideration those reviews whose score = 3\n",
    "filtered_data = pd.read_sql_query('select * from reviews where score != 3 limit 100000', con)\n",
    "\n",
    "print('Number of datapoints in our data {}'.format(filtered_data.shape))\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      1  1303862400   \n",
       "1                     0                       0      0  1346976000   \n",
       "2                     1                       1      1  1219017600   \n",
       "3                     3                       3      0  1307923200   \n",
       "4                     0                       0      1  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give reviews with a score > 3 a positive rating,\n",
    "# and reviews with a score < 3 a negative rating\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 0 # negative\n",
    "    return 1 # positive\n",
    "\n",
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition)\n",
    "filtered_data['Score'] = positiveNegative\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning : Deduplication\n",
    "\n",
    "It is observed (as shown in the table below) that the reviews data had many duplicate entries. Hence it was necessary to remove duplicates in order to get unbiased results for the analysis of the data.\n",
    "\n",
    "Following is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67901</th>\n",
       "      <td>73791</td>\n",
       "      <td>B000HDOPZG</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72060</th>\n",
       "      <td>78445</td>\n",
       "      <td>B000HDL1RQ</td>\n",
       "      <td>AR5J8UI46CURR</td>\n",
       "      <td>Geetha Krishnan</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1199577600</td>\n",
       "      <td>LOACKER QUADRATINI VANILLA WAFERS</td>\n",
       "      <td>DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id   ProductId         UserId      ProfileName  \\\n",
       "67901  73791  B000HDOPZG  AR5J8UI46CURR  Geetha Krishnan   \n",
       "72060  78445  B000HDL1RQ  AR5J8UI46CURR  Geetha Krishnan   \n",
       "\n",
       "       HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "67901                     2                       2      1  1199577600   \n",
       "72060                     2                       2      1  1199577600   \n",
       "\n",
       "                                 Summary  \\\n",
       "67901  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "72060  LOACKER QUADRATINI VANILLA WAFERS   \n",
       "\n",
       "                                                    Text  \n",
       "67901  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  \n",
       "72060  DELICIOUS WAFERS. I FIND THAT EUROPEAN WAFERS ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data[filtered_data['UserId'] == 'AR5J8UI46CURR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As can be seen above the same user has multiple reviews with the same values for HelpfulnessNumerator, HelpfulnessDenominator, Score, Time, Summary and Text and on doing analysis it was found that \n",
    "\n",
    "  ProductId=B000HDOPZG was Loacker Quadratini Vanilla Wafer Cookies, 8.82-Ounce Packages (Pack of 8)\n",
    "\n",
    "  ProductId=B000HDL1RQ was Loacker Quadratini Lemon Wafer Cookies, 8.82-Ounce Packages (Pack of 8) and so on\n",
    "  \n",
    "\n",
    "- It was inferred after analysis that reviews with same parameters other than ProductId belonged to the same product just having different flavour or quantity. Hence in order to reduce redundency it was decided to eliminate the rows having same parameters.\n",
    "\n",
    "\n",
    "- The method used to eliminate was that we first sort the data according to ProductId and then just keep the first similar product review and delete the others. For eg. in the above just the review for ProductId=B000HDL1RQ remains. This method ensures that there is only one representative for each product and deduplication without sorting would lead to possibility of different representatives still existing for the same product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting data according to ProductId in ascending order\n",
    "sorted_data = filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87775, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deduplication of entries\n",
    "final = filtered_data.drop_duplicates(subset={\"UserId\", \"ProfileName\", \"Time\", \"Text\"}, keep='first', inplace=False)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.775"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see how much % of data still remains\n",
    "(final.size / filtered_data.size) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation : </b>It was also seen that in two rows given below the value of HelpfulnessNumerator is greater than HelpfulnessDenominator which is not practically possible hence these two rows too are removed from calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41159</th>\n",
       "      <td>44737</td>\n",
       "      <td>B001EQ55RW</td>\n",
       "      <td>A2V0I904FH7ABY</td>\n",
       "      <td>Ram</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1212883200</td>\n",
       "      <td>Pure cocoa taste with crunchy almonds inside</td>\n",
       "      <td>It was almost a 'love at first bite' - the per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59301</th>\n",
       "      <td>64422</td>\n",
       "      <td>B000MIDROQ</td>\n",
       "      <td>A161DK06JJMCYF</td>\n",
       "      <td>J. E. Stephens \"Jeanne\"</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1224892800</td>\n",
       "      <td>Bought This for My Son at College</td>\n",
       "      <td>My son loves spaghetti so I didn't hesitate or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id   ProductId          UserId              ProfileName  \\\n",
       "41159  44737  B001EQ55RW  A2V0I904FH7ABY                      Ram   \n",
       "59301  64422  B000MIDROQ  A161DK06JJMCYF  J. E. Stephens \"Jeanne\"   \n",
       "\n",
       "       HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "41159                     3                       2      1  1212883200   \n",
       "59301                     3                       1      1  1224892800   \n",
       "\n",
       "                                            Summary  \\\n",
       "41159  Pure cocoa taste with crunchy almonds inside   \n",
       "59301             Bought This for My Son at College   \n",
       "\n",
       "                                                    Text  \n",
       "41159  It was almost a 'love at first bite' - the per...  \n",
       "59301  My son loves spaghetti so I didn't hesitate or...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final[final['HelpfulnessNumerator'] > final['HelpfulnessDenominator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[final['HelpfulnessNumerator'] <= final['HelpfulnessDenominator']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87773, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    73592\n",
       "0    14181\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before starting the next phase of preprocessing lets see the number of entries left\n",
    "print(final.shape)\n",
    "\n",
    "# How many positive and negative reviews are present in our dataset ?\n",
    "final['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing: Stemming, stop-word removal and Lemmatization\n",
    "\n",
    "Now that we have finished deduplication our data requires some preprocessing before we go on further with analysis\n",
    "and making the prediction model.\n",
    "\n",
    "Hence in Preprocessing phase we do following in the order below:-\n",
    "\n",
    "1. Begin by removing html tags\n",
    "2. Remove any punctuations or limited set of special characters like , or . or # etc.\n",
    "3. Check if the word is made up of english letters and is not alpha-numeric.\n",
    "4. Check to see if the length of the word is greater than 2 (as it was researched that there is no adjective in 2-letters)\n",
    "5. Convert the word to lowercase.\n",
    "6. Remove Stopwords.\n",
    "7. Finally Snowball stemming the word (it was observed to be better than Porter Stemming)\n",
    "\n",
    "After which we collect the words used to describe positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "I don't know if it's the cactus or the tequila or just the unique combination of ingredients, but the flavour of this hot sauce makes it one of a kind!  We picked up a bottle once on a trip we were on and brought it back home with us and were totally blown away!  When we realized that we simply couldn't find it anywhere in our city we were bummed.<br /><br />Now, because of the magic of the internet, we have a case of the sauce and are ecstatic because of it.<br /><br />If you love hot sauce..I mean really love hot sauce, but don't want a sauce that tastelessly burns your throat, grab a bottle of Tequila Picante Gourmet de Inclan.  Just realize that once you taste it, you will never want to use any other sauce.<br /><br />Thank you for the personal, incredible service!\n"
     ]
    }
   ],
   "source": [
    "# finding sentences containing HTML tags\n",
    "import re\n",
    "i = 0\n",
    "for sent in final['Text'].values:\n",
    "    if len(re.findall('<.*?>', sent)) > 0:\n",
    "        print(i)\n",
    "        print(sent)\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining some helper functions for text preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stop = set(stopwords.words('english')) # set of stopwords\n",
    "sno = SnowballStemmer('english') # initialising the snowball stemmer\n",
    "\n",
    "def cleanhtml(sentence): # function to clean html tags from sentence\n",
    "    tag = re.compile('<.*?>')\n",
    "    clean_sentence = re.sub(tag, ' ', sentence)\n",
    "    return clean_sentence\n",
    "\n",
    "def cleanpunc(sentence): # function to clean the sentence from any punctuation or special characters\n",
    "    clean_sentence = re.sub(r'[?|!|\\'|\"|#]', r'', sentence)\n",
    "    clean_sentence = re.sub(r'[.|,|)|(|\\|/]', r' ', clean_sentence)\n",
    "    return clean_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'himself', \"wasn't\", \"you'll\", 'any', 'm', \"mightn't\", 'nor', 'that', 'me', 'herself', 'mustn', 'more', 'down', 'wasn', 'd', 'wouldn', 'yourself', 'them', 'shouldn', 'from', \"aren't\", \"hasn't\", 'ain', 'has', 'doing', 'isn', 'yours', 'themselves', 'ma', 'they', 'those', 'why', 'before', 'mightn', \"haven't\", 'it', 'been', \"that'll\", 'theirs', 'weren', \"you've\", 'whom', 'then', 'couldn', 'him', 'is', 'an', 'hers', 'over', \"don't\", 'hasn', 'into', 'were', 'shan', 'all', 'about', \"couldn't\", 'until', 'his', 't', \"needn't\", 'other', \"won't\", 'do', \"doesn't\", 'hadn', 'am', 're', 'out', 'now', 'be', 've', 'their', 'being', 'above', 'she', 'having', 'which', 'up', 'ourselves', \"you're\", 'aren', 'itself', \"weren't\", 'our', 'doesn', 'your', \"shan't\", 'will', 'most', 'll', 'can', 'here', \"should've\", 'so', 'in', 'ours', 'to', 'too', 'where', 'each', 'you', 'just', 'o', 'didn', 'yourselves', \"you'd\", 'i', 'below', 'some', 'than', 'very', 'have', 'the', 'who', 'her', 'he', 'what', 'under', 'this', \"it's\", 'had', 'at', 'there', 'off', 'few', 'with', 'own', 'my', 's', 'after', 'these', 'we', 'don', 'further', 'during', 'and', 'while', 'between', 'because', 'on', 'a', \"didn't\", \"isn't\", 'through', \"hadn't\", 'once', 'won', 'such', 'needn', 'are', 'but', 'only', 'was', 'does', 'myself', 'of', 'by', 'against', \"mustn't\", 'same', 'did', \"shouldn't\", 'when', 'not', \"she's\", 'as', 'how', \"wouldn't\", 'its', 'should', 'for', 'again', 'haven', 'if', 'no', 'y', 'or', 'both'}\n",
      "***************************************************\n",
      "tasti\n"
     ]
    }
   ],
   "source": [
    "print(stop)\n",
    "print('***************************************************')\n",
    "print(sno.stem('tasty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87773/87773 [01:46<00:00, 822.43it/s] \n"
     ]
    }
   ],
   "source": [
    "# Code for implementing step-by-step the checks mentioned in the pre-processing phase\n",
    "# The code takes a while to run as it needs to run on 100k sentences.\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "if not os.path.isfile('final.sqlite'):\n",
    "    i = 0\n",
    "    cleaned_reviews = []\n",
    "    all_positive_words = [] # store words from positive reviews here\n",
    "    all_negative_words = [] # store words from negative reviews here\n",
    "    for sent in tqdm(final['Text'].values):\n",
    "        cleaned_words = [] # storing each cleaned word from sent\n",
    "        sent = cleanhtml(sent) # remove html tags\n",
    "        for w in sent.split():\n",
    "            for cleaned_word in cleanpunc(w).split():\n",
    "                if cleaned_word.isalpha() and len(cleaned_word)>2:\n",
    "                    if cleaned_word.lower() not in stop: # stopword removal\n",
    "                        s = (sno.stem(cleaned_word.lower())).encode('utf8') # stemming\n",
    "                        cleaned_words.append(s)\n",
    "                        if final['Score'].values[i] == 1:\n",
    "                            all_positive_words.append(s) # list of all words used to describe positive reviews\n",
    "                        if final['Score'].values[i] == 0:\n",
    "                            all_negative_words.append(s) # list of all words used to describe negative reviews\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    continue\n",
    "        str1 = b\" \".join(cleaned_words) # final string of cleaned words\n",
    "        cleaned_reviews.append(str1)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "if not os.path.isfile('final.sqlite'):\n",
    "    ############-------- storing the preprocessed data into .sqlite file --------#############\n",
    "    final['CleanedText'] = cleaned_reviews # adding a column of CleanedText which displays the data after pre-processing of the review\n",
    "    final['CleanedText'] = final['CleanedText'].str.decode('utf-8')\n",
    "    # store final table into a SQLite table for future.\n",
    "    conn = sqlite3.connect('final.sqlite')\n",
    "    c = conn.cursor()\n",
    "    conn.text_factory = str\n",
    "    final.to_sql('Reviews', conn, if_exists='replace')\n",
    "    conn.close()\n",
    "    \n",
    "    with open('positive_words.pkl', 'wb') as f:\n",
    "        pickle.dump(all_positive_words, f)\n",
    "    with open('negative_words.pkl', 'wb') as f:\n",
    "        pickle.dump(all_negative_words, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
